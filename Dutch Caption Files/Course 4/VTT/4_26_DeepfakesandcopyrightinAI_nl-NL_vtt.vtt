WEBVTT

1
00:03.625 --> 00:05.958
Stel je voor dat je door je
mobiele telefoon bladert,

2
00:06.042 --> 00:08.583
en dat je een video tegenkomt
van een beroemd iemand

3
00:08.667 --> 00:10.542
die iets controversieels zegt.

4
00:11.125 --> 00:13.292
Je bent verbijsterd,
maar dan herinner je je:

5
00:13.375 --> 00:15.083
het zou een deepfake kunnen zijn.

6
00:15.792 --> 00:18.375
Een deepfake is
frauduleuze inhoud,

7
00:18.458 --> 00:20.125
meestal audio of video,

8
00:20.292 --> 00:22.458
die is gemanipuleerd
of gecreëerd

9
00:22.542 --> 00:24.250
met behulp van kunstmatige intelligentie.

10
00:25.208 --> 00:27.750
Deepfakes gebruiken
geavanceerde AI-technieken

11
00:27.833 --> 00:30.958
om de stem en/of afbeelding
van een bestaand iemand

12
00:31.042 --> 00:33.583
te vervangen door griezelig gelijkende
kunstmatige evenbeelden.

13
00:34.750 --> 00:37.458
Deze technologie heeft het
steeds moeilijker gemaakt

14
00:37.542 --> 00:40.917
om te onderscheiden of iets wat je ziet
of hoort op het internet echt is.

15
00:41.667 --> 00:44.958
Deepfakes worden vaak gebruikt
om desinformatie te verspreiden

16
00:45.083 --> 00:48.208
en kan worden gebruikt
bij oplichting, verkiezingsmanipulatie,

17
00:48.375 --> 00:51.208
social engineering-aanvallen
en andere vormen van fraude.

18
00:52.208 --> 00:55.250
Het besef dat het bestrijden
van deepfakes dringend nodig is,

19
00:55.333 --> 00:59.708
heeft de technologiesector, waaronder
bedrijven die AI-modellen helpen ontwikkelen

20
00:59.792 --> 01:02.250
en diensten voor de consument
zoals Microsoft,

21
01:02.333 --> 01:03.375
ertoe aangezet maatregelen te nemen.

22
01:03.917 --> 01:06.042
Deze inspanningen hebben zich
in de loop der tijd verder ontwikkeld,

23
01:06.250 --> 01:09.583
van het invoeren van
voorzieningen tegen namaak

24
01:09.667 --> 01:12.250
tot het bevorderen van digitale
beschermingstechnologieën.

25
01:12.750 --> 01:14.417
Dit is wat de tech-sector
doet:

26
01:14.958 --> 01:16.875
1. Een veilige omgeving opbouwen:

27
01:17.167 --> 01:19.458
Er worden veiligheidsmaatregelen
genomen om ervoor te zorgen dat

28
01:19.542 --> 01:21.708
alles soepel en veilig verloopt.

29
01:22.708 --> 01:25.292
Dit omvat dingen
als voortdurende controles,

30
01:25.500 --> 01:27.833
slecht gedrag blokkeren
en snel maatregelen nemen

31
01:27.917 --> 01:30.042
tegen mensen die het systeem misbruiken.

32
01:31.083 --> 01:32.792
2. Verificatie van de inhoud:

33
01:33.000 --> 01:36.125
Om onechte video's, afbeeldingen
of audio te bestrijden,

34
01:36.750 --> 01:41.042
worden er speciale markeringen of
symbolen toegevoegd aan AI-gecreëerde inhoud.

35
01:41.792 --> 01:42.792
Dit helpt bij het bepalen van

36
01:42.875 --> 01:45.083
de oorsprong en geschiedenis
van de inhoud.

37
01:45.708 --> 01:47.417
3. Diensten veilig houden:

38
01:47.833 --> 01:50.042
Er worden inspanningen gedaan om
schadelijke en misleidende inhoud

39
01:50.125 --> 01:53.167
te herkennen en van
online platforms te verwijderen.

40
01:53.833 --> 01:57.458
Dit zorgt ervoor dat de online ruimte
voor iedereen veilig en respectvol blijft.

41
01:58.458 --> 02:00.000
4. Samenwerken:

42
02:00.292 --> 02:04.167
Net zoals samenwerking de sleutel is
tot het bereiken van gedeelde doelen,

43
02:04.375 --> 02:06.375
kunnen mensen
in de technologie-industrie,

44
02:06.458 --> 02:09.250
organisaties
toegewijd aan maatschappelijk welzijn

45
02:09.458 --> 02:11.542
en overheidsinstanties
die samenkomen,

46
02:11.750 --> 02:13.667
collectief bijdragen

47
02:13.750 --> 02:16.167
aan het creëren van een
veiligere online omgeving.

48
02:16.917 --> 02:18.375
Deze geïntegreerde aanpak

49
02:18.458 --> 02:21.583
kan leiden tot innovatieve oplossingen
en sterkere bescherming

50
02:21.667 --> 02:23.292
voor iedereen in de digitale ruimte.

51
02:24.083 --> 02:26.917
5. Wetten aanpassen aan nieuwe uitdagingen:

52
02:27.125 --> 02:28.625
Naarmate zich nieuwe uitdagingen voordoen,

53
02:28.708 --> 02:31.417
worden er inspanningen geleverd
om nieuwe wetten en initiatieven te ontwikkelen

54
02:31.500 --> 02:33.042
om mensen tegen misbruik te beschermen.

55
02:33.542 --> 02:35.250
6. Het publiek voorlichten:

56
02:35.333 --> 02:37.708
Het is belangrijk voor iedereen
om goed geïnformeerd te zijn.

57
02:38.625 --> 02:41.042
Er zijn initiatieven gaande
om mensen in staat te stellen

58
02:41.125 --> 02:43.917
echte inhoud te onderscheiden
van valse inhoud.

59
02:44.958 --> 02:47.417
Dit omvat de ontwikkeling
van nieuwe hulpmiddelen

60
02:47.500 --> 02:49.625
en educatieve programma's
voor het publiek.

61
02:50.833 --> 02:53.917
Deze strategieën zijn erop gericht
de dingen transparanter

62
02:54.000 --> 02:57.250
en de samenleving weerbaarder
te maken tegen deepfakes.

63
02:57.750 --> 03:01.042
Hoewel deepfakes
ethische en veiligheidsproblemen opleveren

64
03:01.250 --> 03:04.208
vanwege hun potentiële misbruik
en het verspreiden van desinformatie

65
03:04.292 --> 03:05.458
en imitatie,

66
03:05.833 --> 03:09.292
boekt AI-technologie ook vooruitgang
in het met hoge nauwkeurigheid

67
03:09.375 --> 03:10.500
detecteren van deepfakes.

68
03:11.000 --> 03:13.250
Dit brengt ons bij
een ander belangrijk onderwerp:

69
03:13.458 --> 03:16.458
de opkomst en bewustwording
van AI-gegenereerde inhoud.

70
03:17.167 --> 03:19.167
Auteursrecht is een juridisch concept

71
03:19.250 --> 03:21.958
dat makers en auteurs
van origineel werk

72
03:22.042 --> 03:24.583
de exclusieve rechten verschaft
op het gebruik en de distributie ervan,

73
03:24.792 --> 03:27.917
ervoor zorgend dat ze erkenning krijgen
en financieel voordeel hebben

74
03:28.000 --> 03:29.125
van hun creaties.

75
03:29.583 --> 03:33.125
Maar wat gebeurt er
als de maker AI is?

76
03:33.792 --> 03:36.875
Door het besef dat auteursrecht
een belangrijk onderwerp is

77
03:36.958 --> 03:38.708
om aan te pakken
voor AI-gegenereerde inhoud,

78
03:38.917 --> 03:42.542
zijn er initiatieven ontwikkeld zoals de
Microsoft Copilot Copyright Commitment

79
03:42.708 --> 03:44.125
om bestaande beveiligingsondersteuning

80
03:44.208 --> 03:47.083
voor intellectueel eigendom
uit te breiden naar

81
03:47.167 --> 03:49.083
commerciële Copilot-diensten.

82
03:49.583 --> 03:53.375
Deze bereidheid gaat in op de mogelijke
aansprakelijkheid voor inbreuk op

83
03:53.458 --> 03:55.667
intellectuele eigendomsrechten die
zouden kunnen voortvloeien uit

84
03:55.750 --> 03:59.125
het gebruik van de resultaten van
Microsoft Copilot en de Azure OpenAI-dienst.

85
03:59.625 --> 04:02.458
Om het vertrouwen
in AI-gegenereerde inhoud

86
04:02.667 --> 04:05.333
verder te vergroten heeft Microsoft
verificatie van inhoud ontwikkeld.

87
04:06.042 --> 04:08.417
Deze voorziening
gebruikt cryptografische methoden

88
04:08.500 --> 04:10.792
om een onzichtbaar digitaal watermerk
toe te voegen aan

89
04:10.875 --> 04:13.292
alle AI-gegenereerde afbeeldingen in Bing,

90
04:13.542 --> 04:16.542
inclusief de tijd en datum waarop
ze oorspronkelijk zijn aangemaakt.

91
04:17.167 --> 04:19.458
Dit helpt bij het bepalen
waar de inhoud vandaankomt

92
04:19.750 --> 04:22.125
en geeft degenen
die inhoud maken en delen

93
04:22.208 --> 04:24.250
betere hulpmiddelen
om te beslissen wat te vertrouwen is.

94
04:25.042 --> 04:28.875
Dit is een cruciale stap
om ervoor te zorgen

95
04:28.958 --> 04:30.792
dat we AI-technologie op een veilige
en verantwoorde manier gebruiken.

96
04:31.208 --> 04:33.125
Het is belangrijk om op de hoogte te blijven.

97
04:33.750 --> 04:37.208
Onthoud dat niet alles
wat je ziet of hoort de waarheid is,

98
04:37.292 --> 04:39.792
dus als het gaat om
AI-gegenereerde inhoud

99
04:40.000 --> 04:41.708
is het belangrijk om je rechten te kennen

100
04:41.792 --> 04:43.875
en de maatregelen die zijn getroffen
om ze te beschermen.