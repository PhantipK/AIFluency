WEBVTT

1
00:03.083 --> 00:06.000
Naarmate AI zich meer en meer
in ons leven integreert,

2
00:06.167 --> 00:09.917
is het belangrijk om ons af te vragen hoe we
ervoor zorgen dat het verantwoord wordt gebruikt?

3
00:11.083 --> 00:12.083
Laten we dit eens nader bekijken.

4
00:13.042 --> 00:15.417
AI begrijpen
is de eerste stap.

5
00:16.208 --> 00:17.542
Het is niet alleen een modewoord,

6
00:17.708 --> 00:19.750
het is een tool met allerlei mogelijkheden

7
00:19.917 --> 00:22.208
en het is belangrijk
de basisprincipes ervan te begrijpen.

8
00:23.458 --> 00:26.000
Op de hoogte blijven
van de nieuwste ontwikkelingen

9
00:26.167 --> 00:28.875
en ethische discussies
op het gebied van AI is essentieel.

10
00:30.083 --> 00:33.417
Deze kennis is de sleutel om AI
op een verantwoorde manier te gebruiken.

11
00:34.542 --> 00:37.292
AI kan net als wij
blinde vlekken hebben.

12
00:38.458 --> 00:42.458
Het kan maatschappelijke vooroordelen vertonen
die aanwezig zijn in de data waarvan het leert.

13
00:43.542 --> 00:46.083
Door actief op zoek te gaan naar
onbevooroordeelde informatie

14
00:46.250 --> 00:48.958
en te begrijpen hoe AI data gebruikt,

15
00:49.125 --> 00:51.667
wordt het navigeren
door deze blinde vlekken gemakkelijker.

16
00:52.042 --> 00:55.500
Deze aanpak kan ook helpen de vertekening
van machine learning te verminderen.

17
00:56.875 --> 00:58.708
Veiligheid komt altijd op de eerste plaats.

18
00:59.250 --> 01:00.458
Jouw data is kostbaar

19
01:00.625 --> 01:03.667
en je moet weten hoe deze
door AI-systemen wordt gebruikt.

20
01:04.708 --> 01:07.500
Kies diensten die waarde hechten
aan de privacy van gebruikers.

21
01:07.875 --> 01:11.708
De beste AI-systemen geven prioriteit aan
veiligheid en transparantie.

22
01:13.000 --> 01:14.792
Microsoft neemt extra maatregelen

23
01:14.958 --> 01:17.500
om ervoor te zorgen dat jouw data
veilig en beschermd zijn.

24
01:18.542 --> 01:21.750
Zo worden aan het einde
van een chatsessie in Copilot

25
01:21.917 --> 01:24.083
de prompts en antwoorden
gewist.

26
01:25.417 --> 01:27.625
Ook worden de data
van jouw organisatie

27
01:27.792 --> 01:29.833
zonder jouw toestemming
niet gedeeld met derden.

28
01:31.000 --> 01:34.292
Jouw persoonlijke gegevens
moeten tenslotte persoonlijk blijven.

29
01:35.208 --> 01:37.625
Als het gaat om
AI-gegenereerde inhoud,

30
01:37.792 --> 01:40.708
is het essentieel om het niet
zomaar voor waar aan te nemen.

31
01:41.750 --> 01:44.500
Streef er altijd naar
om informatie te verifiëren

32
01:44.667 --> 01:46.167
uit verschillende bronnen

33
01:46.333 --> 01:48.458
en je vermogen
tot kritisch denken te gebruiken.

34
01:49.042 --> 01:53.375
Kritisch denken kan helpen bij het evalueren
en verbeteren van AI-gegenereerde inhoud.

35
01:54.042 --> 01:56.917
Je kunt dit doen door
feiten en bronnen te verifiëren,

36
01:57.083 --> 01:59.917
de doelen van de inhoud
en de doelgroep te begrijpen

37
02:00.292 --> 02:02.542
en verschillende gezichtspunten
in overweging te nemen.

38
02:03.417 --> 02:06.083
Het is ook belangrijk om ervoor te zorgen
dat de AI-tool die je gebruikt

39
02:06.292 --> 02:09.792
duidelijke beleidsregels
en richtlijnen heeft

40
02:09.958 --> 02:11.083
voor het veilige gebruik ervan.

41
02:11.833 --> 02:13.792
Een goed geïnformeerde gebruiker

42
02:14.042 --> 02:16.500
is tenslotte de beste verdediging
tegen onjuiste informatie.

43
02:17.583 --> 02:19.292
AI kan een kracht ten goede zijn.

44
02:19.625 --> 02:21.292
Het kan ons helpen in de gezondheidszorg,

45
02:21.458 --> 02:24.500
het onderwijs en zelfs
bij milieubescherming.

46
02:26.167 --> 02:28.167
Het 'AI for Good'-initiatief van Microsoft

47
02:28.333 --> 02:32.000
is ontworpen om mensen
en organisaties wereldwijd

48
02:32.167 --> 02:35.042
uit te rusten met het vermogen
humanitaire uitdagingen aan te pakken

49
02:35.208 --> 02:38.542
en een wereld te bevorderen die
duurzamer en inclusiever is.

50
02:39.417 --> 02:42.042
Denk bijvoorbeeld eens aan
AI for Good Lab.

51
02:42.500 --> 02:45.000
Het maakt gebruik van AI
om over de hele wereld

52
02:45.167 --> 02:47.542
gemeenschappen te identificeren
die extra steun nodig hebben,

53
02:47.958 --> 02:50.792
vooral degenen die risico lopen
door natuurrampen

54
02:50.958 --> 02:52.500
zoals overstromingen of aardbevingen.

55
02:52.792 --> 02:55.125
Door te bepalen waar
deze gemeenschappen zich bevinden

56
02:55.292 --> 02:57.875
kunnen vitale hulpmiddelen
snel worden ingezet

57
02:58.042 --> 02:59.375
om hun welzijn veilig te stellen.

58
03:00.000 --> 03:02.292
Daarnaast heeft het Fred Hutch Cancer Center,
in samenwerking met Microsoft,

59
03:02.917 --> 03:07.500
het potentieel van AI aangeboord
om QuitBot te ontwikkelen.

60
03:08.458 --> 03:10.958
Deze chatbot biedt hulp
op maat

61
03:11.125 --> 03:13.500
aan mensen die vastbesloten zijn
om te stoppen met roken.

62
03:14.083 --> 03:16.125
AI moet een hulpmiddel voor het goede zijn,

63
03:16.292 --> 03:19.375
nooit een middel om onjuiste informatie
te verspreiden of schade te berokkenen.

64
03:20.625 --> 03:22.000
Wat kun je nog meer doen?

65
03:22.458 --> 03:23.917
Neem deel aan het gesprek.

66
03:24.625 --> 03:27.417
Start discussies
in je gemeenschap en op je werk.

67
03:28.042 --> 03:32.583
Informeer naar het beleid voor
verantwoord gebruik van AI-diensten.

68
03:33.167 --> 03:36.375
Moedig mensen aan om na te denken
over hoe AI wordt gebruikt

69
03:36.542 --> 03:38.750
en om maatregelen te nemen
om misbruik te voorkomen.

70
03:39.667 --> 03:41.500
Door deel te nemen aan deze gesprekken,

71
03:41.792 --> 03:45.042
kun je helpen ervoor te zorgen dat AI
verantwoord wordt gebruikt.

72
03:45.625 --> 03:48.375
Samen kunnen we vorm geven
aan de toekomst van AI.

73
03:49.125 --> 03:51.708
Laten we zorgen dat het een toekomst is
waar we allemaal trots op kunnen zijn.