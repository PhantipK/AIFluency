4_25_PrinciplesofresponsibleAI_en-US
AI is overal om ons heen.

Het is er wanneer je
een spraakassistent vraagt

om je favoriete liedje af te spelen,

of wanneer een chatbot je helpt
met een vraag aan de klantenservice.

Het leidt je naar huis
op je navigatie-app,

en het werkt zelfs
achter de schermen

wanneer je e-mail spam filtert.

Maar heb je je ooit afgevraagd
wat de principes zijn

die het ontwikkelen van deze
AI-systemen sturen?

Hoe zorgen we ervoor dat ze betrouwbaar
en eerlijk zijn en onze privacy respecteren?

De reis naar verantwoorde AI
begint met vertrouwen,

een vertrouwen dat is gebouwd
op zes kernprincipes:

verantwoording, inclusiviteit,
betrouwbaarheid en veiligheid,

eerlijkheid, transparantie,
privacy en beveiliging.

Verantwoording gaat niet alleen
over de ontwikkeling van AI-systemen,

het gaat over verantwoordelijkheid nemen
voor de impact ervan.

Er zijn duidelijke rollen en
verantwoordelijkheden vastgelegd

binnen ontwikkelteams
en organisaties.

Inclusiviteit gaat over het ontwerpen van
AI-oplossingen met iedereen in gedachten

en ervoor zorgen dat de voordelen
van AI voor iedereen toegankelijk zijn.

Betrouwbaarheid en veiligheid
worden bereikt door rigoureus

te testen, valideren
en voortdurend te controleren.

Veiligheidsmaatregelen zijn onder meer
uitvalbeveiliging, foutafhandeling

en bescherming tegen aanvallen.

Eerlijkheid wil zeggen dat iedereen
gelijk behandeld wordt.

Regelmatige beoordelingen
zorgen ervoor dat AI-systemen

niet een bepaalde groep bevoordelen

gebaseerd op ras, geslacht,
of andere kenmerken.

Transparantie is de sleutel tot
het kweken van vertrouwen.

Het stelt gebruikers in staat om de
beslissingen en resultaten van AI te begrijpen.

Privacy en beveiliging gaan over het
respecteren en beschermen van je data.

Alleen noodzakelijke data worden verzameld
en gebruikers hebben controle over hun data.

Er zijn veiligheidsmaatregelen
getroffen om onbevoegde toegang

en inbreuken tegen
te gaan.

Er zijn talloze hulpmiddelen
beschikbaar om te helpen

bij de ontwikkeling,
het gebruik en de verbetering van AI.

Deze hulpmiddelen
kunnen ontwikkelaars

door de verantwoorde evolutie
van AI-technologieën begeleiden.

Ze kunnen bij alles hulp bieden,

van het identificeren van fouten
en het beoordelen van eerlijkheid,

tot het onderzoeken van data en inzicht
in het besluitvormingsproces van AI.

Dit zorgt ervoor dat de AI-systemen
betrouwbaar, eerlijk en transparant zijn.

Een voorbeeld die deze
verantwoorde AI-praktijken

uitdraagt is Microsoft Copilot.

Het geeft prioriteit aan de privacy van
de gebruikersdata en geeft jou de controle erover.

Het biedt contextbewuste
suggesties,

waardoor gebruikers kunnen begrijpen
hoe het tot een aanbeveling is gekomen.

Het probeert alle gebruikers in gelijke mate
te helpen en wordt grondig getest

om de betrouwbaarheid
en veiligheid te handhaven.

De benadering bij het ontwikkelen
van AI is dynamisch, niet statisch.

Voortdurend leren van ervaringen,
feedback van gebruikers,

en vooruitgang op dit gebied zijn een
integraal onderdeel van het verbeteren

van AI-systemen en -praktijken.

Samenwerking en een open dialoog
met de verschillende belanghebbenden,

waaronder gebruikers,
partners, beleidsmakers

en het bredere publiek, zijn nodig.

Naleving van alle relevante wetten
en voorschriften

met betrekking tot AI is een verplichting,

samen met het pleiten voor doordacht
en geïnformeerd AI-beleid

dat een evenwicht vindt tussen innovatie
en de bescherming van gebruikers.

Het ontwikkelen van verantwoorde AI
is een proces

dat veel belang hecht
aan zes kernprincipes:

verantwoording, inclusiviteit,
betrouwbaarheid en veiligheid,

eerlijkheid, transparantie,
privacy en beveiliging.

Het doel van deze principes
is om AI-systemen te creëren

die niet alleen de samenleving
ten goede komen,

maar ook individuele rechten
en waarden respecteren.