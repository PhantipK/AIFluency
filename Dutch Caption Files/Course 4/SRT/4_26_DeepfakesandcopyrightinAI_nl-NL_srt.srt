1
00:00:03,625 --> 00:00:05,958
Stel je voor dat je door je
mobiele telefoon bladert,

2
00:00:06,042 --> 00:00:08,583
en dat je een video tegenkomt
van een beroemd iemand

3
00:00:08,667 --> 00:00:10,542
die iets controversieels zegt.

4
00:00:11,125 --> 00:00:13,292
Je bent verbijsterd,
maar dan herinner je je:

5
00:00:13,375 --> 00:00:15,083
het zou een deepfake kunnen zijn.

6
00:00:15,792 --> 00:00:18,375
Een deepfake is
frauduleuze inhoud,

7
00:00:18,458 --> 00:00:20,125
meestal audio of video,

8
00:00:20,292 --> 00:00:22,458
die is gemanipuleerd
of gecreëerd

9
00:00:22,542 --> 00:00:24,250
met behulp van kunstmatige intelligentie.

10
00:00:25,208 --> 00:00:27,750
Deepfakes gebruiken
geavanceerde AI-technieken

11
00:00:27,833 --> 00:00:30,958
om de stem en/of afbeelding
van een bestaand iemand

12
00:00:31,042 --> 00:00:33,583
te vervangen door griezelig gelijkende
kunstmatige evenbeelden.

13
00:00:34,750 --> 00:00:37,458
Deze technologie heeft het
steeds moeilijker gemaakt

14
00:00:37,542 --> 00:00:40,917
om te onderscheiden of iets wat je ziet
of hoort op het internet echt is.

15
00:00:41,667 --> 00:00:44,958
Deepfakes worden vaak gebruikt
om desinformatie te verspreiden

16
00:00:45,083 --> 00:00:48,208
en kan worden gebruikt
bij oplichting, verkiezingsmanipulatie,

17
00:00:48,375 --> 00:00:51,208
social engineering-aanvallen 
en andere vormen van fraude.

18
00:00:52,208 --> 00:00:55,250
Het besef dat het bestrijden
van deepfakes dringend nodig is,

19
00:00:55,333 --> 00:00:59,708
heeft de technologiesector, waaronder 
bedrijven die AI-modellen helpen ontwikkelen

20
00:00:59,792 --> 00:01:02,250
en diensten voor de consument
zoals Microsoft,

21
00:01:02,333 --> 00:01:03,375
ertoe aangezet maatregelen te nemen.

22
00:01:03,917 --> 00:01:06,042
Deze inspanningen hebben zich 
in de loop der tijd verder ontwikkeld,

23
00:01:06,250 --> 00:01:09,583
van het invoeren van
voorzieningen tegen namaak

24
00:01:09,667 --> 00:01:12,250
tot het bevorderen van digitale
beschermingstechnologieën.

25
00:01:12,750 --> 00:01:14,417
Dit is wat de tech-sector
doet:

26
00:01:14,958 --> 00:01:16,875
1. Een veilige omgeving opbouwen:

27
00:01:17,167 --> 00:01:19,458
Er worden veiligheidsmaatregelen
genomen om ervoor te zorgen dat

28
00:01:19,542 --> 00:01:21,708
alles soepel en veilig verloopt.

29
00:01:22,708 --> 00:01:25,292
Dit omvat dingen
als voortdurende controles,

30
00:01:25,500 --> 00:01:27,833
slecht gedrag blokkeren
en snel maatregelen nemen

31
00:01:27,917 --> 00:01:30,042
tegen mensen die het systeem misbruiken.

32
00:01:31,083 --> 00:01:32,792
2. Verificatie van de inhoud:

33
00:01:33,000 --> 00:01:36,125
Om onechte video's, afbeeldingen
of audio te bestrijden,

34
00:01:36,750 --> 00:01:41,042
worden er speciale markeringen of
symbolen toegevoegd aan AI-gecreëerde inhoud.

35
00:01:41,792 --> 00:01:42,792
Dit helpt bij het bepalen van

36
00:01:42,875 --> 00:01:45,083
de oorsprong en geschiedenis
van de inhoud.

37
00:01:45,708 --> 00:01:47,417
3. Diensten veilig houden:

38
00:01:47,833 --> 00:01:50,042
Er worden inspanningen gedaan om
schadelijke en misleidende inhoud

39
00:01:50,125 --> 00:01:53,167
te herkennen en van
online platforms te verwijderen.

40
00:01:53,833 --> 00:01:57,458
Dit zorgt ervoor dat de online ruimte
voor iedereen veilig en respectvol blijft.

41
00:01:58,458 --> 00:02:00,000
4. Samenwerken:

42
00:02:00,292 --> 00:02:04,167
Net zoals samenwerking de sleutel is
tot het bereiken van gedeelde doelen,

43
00:02:04,375 --> 00:02:06,375
kunnen mensen
in de technologie-industrie,

44
00:02:06,458 --> 00:02:09,250
organisaties
toegewijd aan maatschappelijk welzijn

45
00:02:09,458 --> 00:02:11,542
en overheidsinstanties
die samenkomen,

46
00:02:11,750 --> 00:02:13,667
collectief bijdragen

47
00:02:13,750 --> 00:02:16,167
aan het creëren van een
veiligere online omgeving.

48
00:02:16,917 --> 00:02:18,375
Deze geïntegreerde aanpak

49
00:02:18,458 --> 00:02:21,583
kan leiden tot innovatieve oplossingen
en sterkere bescherming

50
00:02:21,667 --> 00:02:23,292
voor iedereen in de digitale ruimte.

51
00:02:24,083 --> 00:02:26,917
5. Wetten aanpassen aan nieuwe uitdagingen:

52
00:02:27,125 --> 00:02:28,625
Naarmate zich nieuwe uitdagingen voordoen,

53
00:02:28,708 --> 00:02:31,417
worden er inspanningen geleverd
om nieuwe wetten en initiatieven te ontwikkelen

54
00:02:31,500 --> 00:02:33,042
om mensen tegen misbruik te beschermen.

55
00:02:33,542 --> 00:02:35,250
6. Het publiek voorlichten:

56
00:02:35,333 --> 00:02:37,708
Het is belangrijk voor iedereen
om goed geïnformeerd te zijn.

57
00:02:38,625 --> 00:02:41,042
Er zijn initiatieven gaande
om mensen in staat te stellen

58
00:02:41,125 --> 00:02:43,917
echte inhoud te onderscheiden
van valse inhoud.

59
00:02:44,958 --> 00:02:47,417
Dit omvat de ontwikkeling
van nieuwe hulpmiddelen

60
00:02:47,500 --> 00:02:49,625
en educatieve programma's
voor het publiek.

61
00:02:50,833 --> 00:02:53,917
Deze strategieën zijn erop gericht
de dingen transparanter

62
00:02:54,000 --> 00:02:57,250
en de samenleving weerbaarder
te maken tegen deepfakes.

63
00:02:57,750 --> 00:03:01,042
Hoewel deepfakes
ethische en veiligheidsproblemen opleveren

64
00:03:01,250 --> 00:03:04,208
vanwege hun potentiële misbruik
en het verspreiden van desinformatie

65
00:03:04,292 --> 00:03:05,458
en imitatie,

66
00:03:05,833 --> 00:03:09,292
boekt AI-technologie ook vooruitgang
in het met hoge nauwkeurigheid

67
00:03:09,375 --> 00:03:10,500
detecteren van deepfakes.

68
00:03:11,000 --> 00:03:13,250
Dit brengt ons bij
een ander belangrijk onderwerp:

69
00:03:13,458 --> 00:03:16,458
de opkomst en bewustwording
van AI-gegenereerde inhoud.

70
00:03:17,167 --> 00:03:19,167
Auteursrecht is een juridisch concept

71
00:03:19,250 --> 00:03:21,958
dat makers en auteurs
van origineel werk

72
00:03:22,042 --> 00:03:24,583
de exclusieve rechten verschaft
op het gebruik en de distributie ervan,

73
00:03:24,792 --> 00:03:27,917
ervoor zorgend dat ze erkenning krijgen
en financieel voordeel hebben

74
00:03:28,000 --> 00:03:29,125
van hun creaties.

75
00:03:29,583 --> 00:03:33,125
Maar wat gebeurt er
als de maker AI is?

76
00:03:33,792 --> 00:03:36,875
Door het besef dat auteursrecht
een belangrijk onderwerp is

77
00:03:36,958 --> 00:03:38,708
om aan te pakken
voor AI-gegenereerde inhoud,

78
00:03:38,917 --> 00:03:42,542
zijn er initiatieven ontwikkeld zoals de
Microsoft Copilot Copyright Commitment

79
00:03:42,708 --> 00:03:44,125
om bestaande beveiligingsondersteuning

80
00:03:44,208 --> 00:03:47,083
voor intellectueel eigendom
uit te breiden naar

81
00:03:47,167 --> 00:03:49,083
commerciële Copilot-diensten.

82
00:03:49,583 --> 00:03:53,375
Deze bereidheid gaat in op de mogelijke
aansprakelijkheid voor inbreuk op

83
00:03:53,458 --> 00:03:55,667
intellectuele eigendomsrechten die
zouden kunnen voortvloeien uit

84
00:03:55,750 --> 00:03:59,125
het gebruik van de resultaten van
Microsoft Copilot en de Azure OpenAI-dienst.

85
00:03:59,625 --> 00:04:02,458
Om het vertrouwen
in AI-gegenereerde inhoud

86
00:04:02,667 --> 00:04:05,333
verder te vergroten heeft Microsoft
verificatie van inhoud ontwikkeld.

87
00:04:06,042 --> 00:04:08,417
Deze voorziening
gebruikt cryptografische methoden

88
00:04:08,500 --> 00:04:10,792
om een onzichtbaar digitaal watermerk
toe te voegen aan

89
00:04:10,875 --> 00:04:13,292
alle AI-gegenereerde afbeeldingen in Bing,

90
00:04:13,542 --> 00:04:16,542
inclusief de tijd en datum waarop
ze oorspronkelijk zijn aangemaakt.

91
00:04:17,167 --> 00:04:19,458
Dit helpt bij het bepalen
waar de inhoud vandaankomt

92
00:04:19,750 --> 00:04:22,125
en geeft degenen
die inhoud maken en delen

93
00:04:22,208 --> 00:04:24,250
betere hulpmiddelen
om te beslissen wat te vertrouwen is.

94
00:04:25,042 --> 00:04:28,875
Dit is een cruciale stap
om ervoor te zorgen

95
00:04:28,958 --> 00:04:30,792
dat we AI-technologie op een veilige
en verantwoorde manier gebruiken.

96
00:04:31,208 --> 00:04:33,125
Het is belangrijk om op de hoogte te blijven.

97
00:04:33,750 --> 00:04:37,208
Onthoud dat niet alles
wat je ziet of hoort de waarheid is,

98
00:04:37,292 --> 00:04:39,792
dus als het gaat om
AI-gegenereerde inhoud

99
00:04:40,000 --> 00:04:41,708
is het belangrijk om je rechten te kennen

100
00:04:41,792 --> 00:04:43,875
en de maatregelen die zijn getroffen
om ze te beschermen.
